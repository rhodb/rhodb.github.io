<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>Brandon  Rhodes | Stress and syllabification with Dynamic Computational Networks</title>
<meta name="description" content="A webpage for people to see what I'm about. If you have any questions about work or projects you see on here, please don't hesitate to reach out via email or LinkedIn.
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->
<link rel="shortcut icon" href="/assets/img/favicon.ico">
<link rel="stylesheet" href="/assets/css/main.css">

<link rel="canonical" href="/projects/dcn/">

<!-- Theming-->

  <script src="/assets/js/theme.js"></script>




    
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <a class="navbar-brand title font-weight-lighter" href="/">
       <span class="font-weight-bold">Brandon</span>   Rhodes
      </a>
      
      <!-- Navbar Toogle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              About
              
            </a>
          </li>
          
          <!-- Blog -->
          <li class="nav-item ">
            <a class="nav-link" href="/blog/">
              Blog
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/projects/">
                Projects
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/publications/">
                Publications
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/teaching/">
                Teaching
                
              </a>
          </li>
          
          
          
          
          
          
        <!-- CV -->
          <li class="nav-item ">
	  <a class="nav-link" target="_blank" href="/assets/pdf/RhodesBrandon_CV.pdf">CV</a>
          </li>
          
            <div class = "toggle-container">
              <a id = "light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
              </a>
            </div>
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h1 class="post-title">Stress and syllabification with Dynamic Computational Networks</h1>
    <p class="post-description">I investigated the possibilities and properties of Dynamic Computational Networks when jointly accounting for stress and syllabification (in English).</p>
  </header>

  <article>
    <h2 id="overview">Overview</h2>

<p>For my dissertation proposal at the University of Chicago, I worked on extending work done by <a href="http://people.cs.uchicago.edu/~jagoldsm/">Goldsmith</a> and Larson in the 1990s on a neural network architecture they called a Dynamic Computational Network (DCN). This was a bunch of fun, as <a href="http://people.cs.uchicago.edu/~jagoldsm/">John</a> was happy to be thinking about this problem again, and it was a way for me to think about how I could relate modern statistical and machine learning methods into a classical problem in linguistics and an previous, and promising, framework for that problem, DCNs. I haven’t done much work since, as I’ve gone off in different directions for the dissertation, but this has always been in the back of my mind, waiting to be revisited. I believe this theory should really be developed, as it is a simple, yet very powerful, framework which does seem to actually set theory on a track towards neurological plausibility — something I feel should be thought about more. This project page will definitely not cover everything in the proposal itself, but please feel free to look at the actual <a href="/assets/pdf/190609_proposal-final.pdf">proposal</a> and <a href="/assets/pdf/190609_presentation.pdf">presentation</a> I gave during my defense of it, which should help clarify points of uncertainty. <a href="https://linguistics.uchicago.edu/jason-riggle">Jason Riggle</a> is the chair, and <a href="190609_presentation">John Goldsmith</a> and <a href="https://signlanguagelab.uchicago.edu/">Diane Brentari</a> are members on my dissertation committee.</p>

<h2 id="preliminaries-and-motivation">Preliminaries and motivation</h2>

<ul>
  <li>
    <p>Stress: think about stress in English as where the emphasis of a word goes: <em>CONduct</em> = noun, <em>conDUCT</em> = verb</p>
  </li>
  <li>
    <p>Syllabification: the syllable structure in a word: <em>about</em> is pronounced as <em>a-bout</em> and not <em>ab-out</em>, so the syllable structure has <em>a</em> and <em>bout</em> separated as <em>a.bout</em> and not <em>ab</em> and <em>out</em> separated as <em>ab.out</em>.</p>
  </li>
</ul>

<p>As with many linguistic phenomena, children are typically not taught this explicitly for the majority of the words they know in their language — <em>they just learn it</em>. So, one of the jobs of the linguist is to uncover the structure in linguistic data, as there must be patterns / structure children exploit to learn language so quickly. Working on the problems of stress and syllabification is interesting because of the similar pattern in them, which I won’t elaborate much on because it gets to be a bit technical. For syllabification, there is an alternating wave of sonority, so think soft sound followed by loud sound followed by soft sound; for stress, there is an alternating wave of stress, so think stressed followed by unstressed followed by (secondary) stress. That explanation is admittedly a massive gloss over of these problems, but it is meant to give the reader who has little linguistic experience some type of context; it is not intended for a professional linguist.</p>

<h2 id="main-ideas">Main ideas</h2>

<p>These networks are essentially a kind of recurrent neural network (RNN); or, DCNs at least most closely resemble RNNs. DCNs differ in a couple of salient ways, though. First, DCNs take a single input embedding for the whole sequence of computations, unlike in (most, if not all) RNNs where at each time step <em>t</em> there is the output from <em>t-1</em> (obtained from computations on the input from time step <em>t-1</em>) and new input at step <em>t</em>. So, in RNN-talk we can think of DCNs as using one input embedding, which is a sequence of linguistically significant values, and then using <strong><em>just</em></strong> the hidden state at each subsequent time step for every calculation. Second, computations persist until an equilibrium is reached, which may not happen if the weights are not constrained in the proper way. The second difference is perhaps analogous to the exploding gradient problem in deep learning. Work I did extended these models by adding another layer at each time step. I did this because Goldsmith and Larson’s previous work looked at syllabification <strong><em>or</em></strong> stress (accent) in a language, and I was looking at syllabification <strong><em>and</em></strong> stress in American English, as I wanted to work on the problem of quantity-sensitive stress systems. Below you will see two photos: the top shows the previous set up, the one found in <a href="http://people.cs.uchicago.edu/~jagoldsm/">Goldsmith</a> and Larson’s works; the second is an instantiation of the general extension to their framework that I proposed.</p>

<div class="row justify-content-md-center">
        <img class="img-fluid rounded z-depth-1" src="/assets/img/210112_dcn-onelayer.png" alt="" title="example image" />
</div>
<div class="caption">
    The original architecture in Goldsmith and Larson's works.
</div>

<div class="row justify-content-md-center">
        <img class="img-fluid rounded z-depth-1" src="/assets/img/210112_dcn-twolayer.png" alt="" title="example image" />
</div>
<div class="caption">
    An instance of the general extension I proposed to their work. We see to account for syllabification and accent and their interactions, we can introduce another layer with connections to the other layer.
</div>

<p>Above in the bottom picture, you see an instantiation of the general extension; below, you can see the general extension itself. The idea is that to account for syllabification and accent jointly, we can introduce another layer and posit various connections between the layers. Each connection and node configuration (i.e. each different architecture) expresses a different way of passing or sharing information. Presumably, different languages will vary by their architecture or settings for the parameters of the architecture, which are denoted by the Greek letters in the diagrams. These parameters basically determine how much information is passed along that connection, affecting the outcome of that information flow. I name the layers as accent and syllabification layers because they correspond to the same (hierarchical) structure which is found in much of the more traditional work on the topic. Typically, we interpret each node in the syllabification layer corresponds to a phoneme and each node on the accent layer corresponds to a syllable; so, under this interpretation, the number of nodes in the accent layer is constrained to be no greater than the number of nodes in the syllabification layer.</p>

<div class="row justify-content-lg-center">
        <img class="img-fluid rounded z-depth-1" src="/assets/img/210112_dcn-jointmodeling.png" alt="" title="example image" />
</div>
<div class="caption">
    The general extension that I proposed. Connections can be uni- or bi-directional; they can exist or not exist; the two layers can have an equal amount of nodes or different (but linguistically it makes most sense for the accent layer to have fewer nodes, as accent is thought of as a property of syllables and not phonemic units).
</div>

<h2 id="learning-the-parameters-a-bit-technical-but-i-wont-go-into-much-detail">Learning the parameters (a bit technical, but I won’t go into much detail)</h2>

<p>One of the interesting parts of working on DCNs is how they are learned. As I said earlier, for each language, there will be a different setting of the parameters, and one question linguists are interested in is how these parameters (or components of one’s language) are learned. Unlike many things in modern machine learning, they are not learned via (stochastic) gradient descent, as there is not a fixed set of computations; computations persist until a certain threshold is reached, and at that point they stop.<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote">1</a></sup> What I did, following <a href="http://people.cs.uchicago.edu/~jagoldsm/">Goldsmith</a> and Larson, was pursue a simulated annealing algorithm. The idea here is that you take a random walk that is constrained in some way — almost similar to Metropolis-Hastings, if you are familiar with that! I won’t talk much about this, but I modified this part to account for the additional layer in the architecture. The extension I think was pretty straightforward, but there are some technical details to work out. Please see the <a href="/assets/pdf/190609_proposal-final.pdf">proposal</a> and/or <a href="/assets/pdf/190609_presentation.pdf">presentation</a> for the details.</p>

<h2 id="results">Results</h2>

<p>As I explained earlier, the computation happens with just one input, so we can compare the original input (inherent) with the final input (derived). The idea is that the linguistic system (the DCN in our case) works to find the best syllabification structure and best stress structure jointly for any given word. If our model is on the right track, this derived output will be similar to what we observe in reality. The example you see here is for the word <em>relegate</em>, which is has stress <em>RElegate</em> and syllabification <em>re.le.gate</em>.</p>

<div class="row justify-content-lg-center">
        <img class="img-fluid rounded z-depth-1" src="/assets/img/210112_dcn-relegate.png" alt="" title="example image" />
</div>
<div class="caption">
    The sonority and accent wave for the word 'relegate'. The inherent sonority wave is in blue and the derived wave (which determines syllabification) is in red; the inherent accent wave is in green and the derived wave (which determines stress) is in yellow. We see the network correctly derives three syllables (three peaks in the red wave), and it correctly places the primary stress on the second syllable, whose nucleus is the vowel in the second position. You can argue the derived accent wave isn't sufficient, thouugh, as there is presumably secondary stress on the last syllable, which doesn't have a peak in that yellow wave. 
</div>

<h2 id="for-more-information">For more information</h2>

<p>Please please please see the <a href="/assets/pdf/190609_proposal-final.pdf">proposal</a> and/or <a href="/assets/pdf/190609_presentation.pdf">presentation</a> I did for more details if you are interested. These project pages are not intended to be in-depth explanations of each work, but rather aimed at giving a general impression for the somewhat interested reader. The more interested reader will (hopefully) be much more satisfied after consulting the actual write-ups. The code for this project will make it into a repository at some point, but I need to do some reorganizing of it first.</p>
<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>Though now that I think of it, I think you could probably do gradient descent… <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>

  </article>

</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    &copy; Copyright 2021 Brandon  Rhodes.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>.

    
  </div>
</footer>



  </body>

  <!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>

<!-- Load DarkMode JS -->
<script src="/assets/js/dark_mode.js"></script>


</html>
